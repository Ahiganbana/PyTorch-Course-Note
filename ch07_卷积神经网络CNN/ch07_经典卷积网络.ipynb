{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 经典卷积网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.1 LeNet-5\n",
    "- 99.2% acc.\n",
    "- 5/6 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.2 AlexNet : ILSVRC 2012 Winner\n",
    "- GTX 580 ( 3GB x 2 )\n",
    "- 11x11\n",
    "- 8 layers\n",
    "\n",
    "**[ImageNet Classification with Deep Convolutional Neural Networks. NIPS2012]**\n",
    "\n",
    "**A. Krizhevsky, I. Sutskever, and G. Hinton**\n",
    "\n",
    "#### Similar framework to LeNet but:\n",
    "- Max pooling, ReLU nonlinearity\n",
    "- More data and bigger model(7 hidden layers, 650k units, 60M params)\n",
    "- GPU implementation(50x speedup over CPU)\n",
    " - Trained on two GPUs for a week\n",
    "- Dropout regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.3 VGGNet: ILSVRC 2014 2nd place\n",
    "- 3x3 filter or\n",
    "- 1x1 filter\n",
    "- 11-19 layers\n",
    "\n",
    "**[Very Deep Convolutional Networks for Large-Scale Image Recognition, ICLR 2015]**\n",
    "\n",
    "**K. Simonyan and A. Zisserman**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.4 GoogLeNet: ILSVRC 2014 1st place\n",
    "- 22 layers\n",
    "- **[Going deeper with convolutions. CVPR2015] C.Szegedy et al.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 ResNet 深度残差网络 ILSVRC 2015 Winner\n",
    "\n",
    "## ResNet\n",
    "\n",
    "- **The residual module**\n",
    " - Introduce skip or shortcut connections(existing before in various forms in literature)\n",
    " - Make it easy for network layers to represent the identity mapping\n",
    " - For some reason, need to skip at least two layers\n",
    " \n",
    " **[Deep Residual Learning for Image Recognition, CVPR2016(Best Paper)]**\n",
    " \n",
    " **Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlk(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(ch_out)\n",
    "        self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d\n",
    "        \n",
    "        self.extra = nn.Sequential()\n",
    "        \n",
    "        if ch_out != ch_in:\n",
    "            self.extra = nn.Sequential(\n",
    "                nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1),\n",
    "                nn.BatchNorm2d(ch_out)\n",
    "            )\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = nn.ReLU(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.extra(x)+out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6 nn.Module\n",
    "\n",
    "### Magic :\n",
    "- Every Layer is nn.Module\n",
    " - nn.Linear\n",
    " - nn.BatchNorm2d\n",
    " - nn.Conv2d\n",
    "- nn.Module nested in nn.Module\n",
    "\n",
    "### 1. embed current layers :\n",
    "- Linear\n",
    "- ReLU\n",
    "- Sigmoid\n",
    "- Conv2d\n",
    "- ConvTransposed2d\n",
    "- Dropout\n",
    "- etc.\n",
    "\n",
    "### 2. Container\n",
    "- net(x)\n",
    "\n",
    "### 3. parameters\n",
    "\n",
    "### 4. modules\n",
    "- modules: all nodes\n",
    "- children: direct children\n",
    "\n",
    "### 5. to(device)\n",
    "\n",
    "### 6. save and load\n",
    "\n",
    "### 7. train / test 切换\n",
    "\n",
    "### 8. implement own layer\n",
    "\n",
    "### 9. own linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.7 Data Argumentation 数据增强\n",
    "\n",
    "### Limited Data\n",
    "- Small network capacity\n",
    "- Regularizaion\n",
    "- Data argumentation\n",
    "\n",
    "### Data argumentation\n",
    "- Flip\n",
    "```Python\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data/', train=True, download=True,\n",
    "                   transform = transforms.Compose([\n",
    "                       transforms.RandomHorizontalFlip(),\n",
    "                       transforms.RandomVerticaalFlip(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,),(0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "```\n",
    "\n",
    "- Rotate\n",
    "```Python\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data/', train=True, download=True,\n",
    "                   transform = transforms.Compose([\n",
    "                       transforms.RandomRotation(15), # 旋转15度\n",
    "                       # 随机选择三个角度中的一个进行旋转\n",
    "                       transforms.RandomRotation([90,180,270]), \n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normaliza((0.1307,),(0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "```\n",
    "\n",
    "- Scale 缩放\n",
    "```Python\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data/', train=True, download=True,\n",
    "                   transform = transforms.Compose([\n",
    "                       transforms.Resize([32,32]) # Scale\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normaliza((0.1307,),(0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "```\n",
    "\n",
    "- Crop Part 裁剪\n",
    "```Python\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data/', train=True, download=True,\n",
    "                   transform = transforms.Compose([\n",
    "                       transforms.RandomCrop([28,28]) # Crop 裁剪\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normaliza((0.1307,),(0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "```\n",
    "\n",
    "- Noise 加入噪声\n",
    "\n",
    "- GAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python35664bitbaseconda34414b764a4544e4b3502fc9f239efc6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
