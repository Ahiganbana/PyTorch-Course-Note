{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch02 PyTorch基础教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 张量数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "print(a.type())\n",
    "print(type(a))\n",
    "isinstance(a,torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note1: 类型推断\n",
    "- tensor_name.type()\n",
    "- isinstance(torsor_name,type_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) torch.Size([]) 0 0\n"
     ]
    }
   ],
   "source": [
    "# 标量 ,dim=0\n",
    "a = torch.tensor(1.)\n",
    "print(a,a.shape,len(a.shape),a.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note2: dim=0 标量\n",
    "- a.shape 成员\n",
    "- a.size() 成员函数\n",
    "- a.dim() 维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1000, 2.2000]) torch.Size([2]) torch.FloatTensor\n",
      "tensor([8.4078e-45, 0.0000e+00]) torch.Size([2]) torch.FloatTensor\n",
      "tensor([1., 1.], dtype=torch.float64) torch.Size([2]) torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "# 向量,dim=1\n",
    "a = torch.tensor([1.1,2.2])\n",
    "print(a,a.shape,a.type())\n",
    "\n",
    "b = torch.FloatTensor(2)\n",
    "print(b,b.shape,b.type())\n",
    "\n",
    "data = np.ones(2)\n",
    "c = torch.from_numpy(data)\n",
    "print(c,c.shape,c.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note3: dim=1 向量\n",
    "- .tensor接受的是数据的内容\n",
    "- .FloatTensor接受的是数据的shape,随机初始化\n",
    "- .from_numpy()  numpy -> torch.tensor\n",
    "- dim=0 -> 0.1\n",
    "- dim=1 -> [0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6025, -0.0328, -1.7973],\n",
      "        [ 0.5828,  0.6371, -0.0266]])\n",
      "torch.Size([2, 3])   2   3\n",
      "用shape索引:  2   3\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3) # normal distribution 正态分布\n",
    "# a = torch.FloatTensor(2,3)\n",
    "print(a)\n",
    "print(a.shape,' ',a.size(0),' ',a.size(1))\n",
    "print('用shape索引: ',a.shape[0],' ',a.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9681, 0.9093, 0.3873],\n",
       "         [0.2986, 0.7554, 0.5381]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])   torch.Size([1, 2, 3])\n",
      "a的内存大小为:1x2x3 =  6\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,2,3)   #  均匀分布[0,1] uniform distribution\n",
    "display(a)\n",
    "print(a.shape,' ',a.size())\n",
    "list(a.shape)\n",
    "print('a的内存大小为:1x2x3 = ',a.numel())\n",
    "print(len(a.shape),a.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note4: dim=3的张量\n",
    "- rand 均匀分布[0,1]\n",
    "- randn 正态分布[0,1]\n",
    "- 为了和python交互,使用list将shape转换为list类型\n",
    "- 用.numel()方法得到tensor的大小\n",
    "- 用len(a.shape)和a.dim()都可得到tensor的维度\n",
    "- 三维张量在RNN经常使用,四维张量在CNN中经常使用,用来表示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 3.3000], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_np = np.array([2,3.3])\n",
    "a_pt = torch.from_numpy(a_np)\n",
    "a_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 3.2000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2.,3.2]) # 小写给具体数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.8863e+36, 4.5790e-41, 9.8866e+36],\n",
       "        [4.5790e-41, 2.7604e+20, 1.7744e+28]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(2,3) # 大写给shape\n",
    "# torch.FloatTensor([2.,3.2]) 少使用,易混淆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "# set default type\n",
    "print(torch.tensor([1.2,3]).type())\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(torch.tensor([1.2,3]).type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note5: tensor和FloatTensor\n",
    "- 小写给具体数据,大写给shape\n",
    "- 这种方法生成的张量不能直接使用,里面会存在无穷大和无穷小,后面必须用别的数据写入\n",
    "- .set_default_tensor_type()方法可以设置tensor的默认类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2782, 0.6091, 0.6666],\n",
      "        [0.3973, 0.5082, 0.8371],\n",
      "        [0.4828, 0.8271, 0.6257]])\n",
      "tensor([[0.2782, 0.6091, 0.6666],\n",
      "        [0.3973, 0.5082, 0.8371],\n",
      "        [0.4828, 0.8271, 0.6257]])\n",
      "tensor([[5, 4, 8],\n",
      "        [3, 3, 2],\n",
      "        [6, 8, 2]])\n"
     ]
    }
   ],
   "source": [
    "# rand\n",
    "a = torch.rand(3,3)\n",
    "print(a)\n",
    "b = torch.rand_like(a)\n",
    "print(a)\n",
    "\n",
    "a = torch.randint(1,10,[3,3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note6: rand/rand_like , randint\n",
    "- rand会均匀随机产生[0,1)之间的数据\n",
    "- *_like方法接收的参数是tensor\n",
    "- .randint(1,10,[3,3])产生[1,10)之间的均匀分布随机数,shape为[3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7122, 0.9045, 0.0039],\n",
      "        [0.8279, 0.5099, 0.2207],\n",
      "        [0.0466, 0.6949, 0.9866]])\n",
      "tensor([ 1.8412,  0.0322,  0.7769,  0.7791,  0.2126,  0.1222, -0.2154,  0.2899,\n",
      "         0.3680,  0.1192])\n",
      "\n",
      "\n",
      "\n",
      "想把tensor全部赋值为一个元素用full: \n",
      " tensor([[7., 7., 7.],\n",
      "        [7., 7., 7.]])\n",
      "生成一个标量:\n",
      " tensor(7.)\n",
      "生成一个vec:\n",
      " tensor([7., 7.])\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# randn正太分布   N(0,1)\n",
    "a = torch.rand(3,3)\n",
    "print(a)\n",
    "\n",
    "# N(u,std)\n",
    "print(torch.normal(mean=torch.full([10],0),std=torch.arange(1,0,-0.1)))\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# full\n",
    "print('想把tensor全部赋值为一个元素用full: \\n',torch.full([2,3],7))\n",
    "print('生成一个标量:\\n',torch.full([],7))\n",
    "print('生成一个vec:\\n',torch.full([2],7))\n",
    "\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note7: randn , full\n",
    "- randn正态分布\n",
    "- full将tensor全部赋值为一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arange生成[0,10)内的等差为2的数列: \n",
      " tensor([0, 2, 4, 6, 8])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# arrange/range\n",
    "print('arange生成[0,10)内的等差为2的数列: \\n',torch.arange(0,10,2))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linespace在[0,10]中生成4个间隔相同的数字: \n",
      " tensor([ 0.0000,  3.3333,  6.6667, 10.0000])\n",
      "logspace在[-1,0]中切割10份,设每个数为xi,生成10^xi: \n",
      " tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292,\n",
      "        0.1000])\n"
     ]
    }
   ],
   "source": [
    "# linespace/logspace\n",
    "print('linespace在[0,10]中生成4个间隔相同的数字: \\n',torch.linspace(0,10,steps=4))\n",
    "print('logspace在[-1,0]中切割10份,设每个数为xi,生成10^xi: \\n',torch.logspace(0,-1,steps=10,base=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note8: arange/range  linespace/logspace\n",
    "- pytorch不建议使用range\n",
    "- arange的第三个参数是等差\n",
    "- linespace的第三个参数是等分的数量\n",
    "- logspace的base参数可以设置为2,10,e等底数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python35664bitbaseconda34414b764a4544e4b3502fc9f239efc6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
